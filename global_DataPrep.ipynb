{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybliometrics\n",
    "pybliometrics.scopus.init()\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch data form SCOPUS API ##\n",
    "\n",
    "base_url = \"https://api.elsevier.com/content/search/scopus\"\n",
    "api_key = \"121d535338908f1887297b3349c4a714\"\n",
    "\n",
    "# Define the base search parameters\n",
    "params = {\n",
    "    'apiKey': api_key,\n",
    "    'count': 25,  # Number of results per page (max allowed by SCOPUS API)\n",
    "    'view': 'STANDARD',\n",
    "}\n",
    "\n",
    "# Function to fetch and process data from SCOPUS API for a specific year\n",
    "def fetch_data_for_year(year, start_index=0, max_records=5500):\n",
    "    retries = 3\n",
    "    delay = 5\n",
    "    query = f\"PUBYEAR = {year}\"\n",
    "    params['query'] = query\n",
    "\n",
    "    records_fetched = 0\n",
    "    result_data = []  # Temporary storage for this year's data\n",
    "\n",
    "    while records_fetched < max_records:\n",
    "        params['start'] = start_index  # Update start index for pagination\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(base_url, params=params)\n",
    "                response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    entries = data.get('search-results', {}).get('entry', [])\n",
    "\n",
    "                    for entry in entries:\n",
    "                        title = entry.get('dc:title', 'No title available')\n",
    "                        authors = entry.get('dc:creator', 'No authors available')\n",
    "                        year = entry.get('prism:coverDate', 'No date available')[:4]\n",
    "                        journal = entry.get('prism:publicationName', 'Unknown Journal')\n",
    "                        language = entry.get('language', 'Unknown Language')\n",
    "                        cited_by_count = entry.get('citedby-count', '0')\n",
    "\n",
    "                        affiliation = \"; \".join(\n",
    "                            aff.get('affilname', 'Unknown Affiliation')\n",
    "                            for aff in entry.get('affiliation', [])\n",
    "                        )\n",
    "\n",
    "                        result_data.append({\n",
    "                            'Title': title,\n",
    "                            'Authors': authors,\n",
    "                            'Year': year,\n",
    "                            'Journal': journal,\n",
    "                            'Language': language,\n",
    "                            'CitedByCount': cited_by_count,\n",
    "                            'Affiliation': affiliation,\n",
    "                        })\n",
    "\n",
    "                    records_fetched += len(entries)\n",
    "                    start_index += params['count']\n",
    "                    print(f\"Fetched {records_fetched} records for {year}...\")\n",
    "                    if records_fetched >= max_records:\n",
    "                        break\n",
    "                else:\n",
    "                    print(f\"Error {response.status_code}: {response.text}\")\n",
    "                    return result_data\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Attempt {attempt + 1} failed with error: {e}\")\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    print(\"Max retries reached. Skipping this request.\")\n",
    "                    return result_data\n",
    "\n",
    "    return result_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the year to fetch data seperately and convert it into CSV ##\n",
    "year = 2018 #(change until reaching 2023)\n",
    "\n",
    "# Fetch data for the given year\n",
    "year_data = fetch_data_for_year(year)\n",
    "\n",
    "# Save the fetched data to a CSV file\n",
    "year_df = pd.DataFrame(year_data)\n",
    "df = year_df.drop(columns='Language')\n",
    "\n",
    "# Drop null and duplicate values\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "year_df.to_csv(f'scopus_data_{year}.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined all CSV from 2018–2023 into a single CSV\n",
    "csv_files = [\n",
    "    'scopus_data_2018.csv',\n",
    "    'scopus_data_2019.csv',\n",
    "    'scopus_data_2020.csv',\n",
    "    'scopus_data_2021.csv',\n",
    "    'scopus_data_2022.csv',\n",
    "    'scopus_data_2023.csv',\n",
    "]\n",
    "\n",
    "# Combine all CSV files into a single DataFrame\n",
    "combined_df = pd.concat((pd.read_csv(file) for file in csv_files), ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv('scopus_combined_data_2018_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Language</th>\n",
       "      <th>CitedByCount</th>\n",
       "      <th>Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Social Progress for Resilient Regions</td>\n",
       "      <td>van Ballekom P.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Region</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>European Investment Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fashion language and translatology</td>\n",
       "      <td>Bojović B.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Babel</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>University of Montenegro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A pragmatic framework to note-taking in consec...</td>\n",
       "      <td>Abuarrah S.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Babel</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>An-Najah National University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Analytic Approximation to the Density of Tw...</td>\n",
       "      <td>Azura R.B.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Recoletos Multidisciplinary Research Journal</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Agusan del Sur State College of Agriculture an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DANCE MOTIFS ON PREHISTORIC POTTERY FROM EASTE...</td>\n",
       "      <td>Turčin I.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Vjesnik Arheoloskog Muzeja u Zagrebu</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Centre for Experimental Archaeology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30045</th>\n",
       "      <td>Second pleurectomy/decortication for a contral...</td>\n",
       "      <td>Furia S.</td>\n",
       "      <td>2023</td>\n",
       "      <td>AME Medical Journal</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Ospedale dell’Angelo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30046</th>\n",
       "      <td>Driving change and quality care in a healthcar...</td>\n",
       "      <td>Cerfolio R.J.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Video-Assisted Thoracic Surgery</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>NYU Langone Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30047</th>\n",
       "      <td>Nephron-sparing surgery for small renal masses...</td>\n",
       "      <td>Gomes D.C.</td>\n",
       "      <td>2023</td>\n",
       "      <td>AME Medical Journal</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>A.C.Camargo Cancer Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30048</th>\n",
       "      <td>From video-assisted mediastinoscopy (VAM) to v...</td>\n",
       "      <td>Martínez S.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Video-Assisted Thoracic Surgery</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Centro de Tratamiento e Investigación sobre Cá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30049</th>\n",
       "      <td>Acute vision loss as an initial manifestation ...</td>\n",
       "      <td>Yong P.J.</td>\n",
       "      <td>2023</td>\n",
       "      <td>AME Medical Journal</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Queen Elizabeth Hospital</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9657 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title          Authors  \\\n",
       "0                  Social Progress for Resilient Regions  van Ballekom P.   \n",
       "2                     Fashion language and translatology       Bojović B.   \n",
       "3      A pragmatic framework to note-taking in consec...      Abuarrah S.   \n",
       "4      An Analytic Approximation to the Density of Tw...       Azura R.B.   \n",
       "5      DANCE MOTIFS ON PREHISTORIC POTTERY FROM EASTE...        Turčin I.   \n",
       "...                                                  ...              ...   \n",
       "30045  Second pleurectomy/decortication for a contral...         Furia S.   \n",
       "30046  Driving change and quality care in a healthcar...    Cerfolio R.J.   \n",
       "30047  Nephron-sparing surgery for small renal masses...       Gomes D.C.   \n",
       "30048  From video-assisted mediastinoscopy (VAM) to v...      Martínez S.   \n",
       "30049  Acute vision loss as an initial manifestation ...        Yong P.J.   \n",
       "\n",
       "       Year                                       Journal          Language  \\\n",
       "0      2018                                        Region  Unknown Language   \n",
       "2      2018                                         Babel  Unknown Language   \n",
       "3      2018                                         Babel  Unknown Language   \n",
       "4      2018  Recoletos Multidisciplinary Research Journal  Unknown Language   \n",
       "5      2018          Vjesnik Arheoloskog Muzeja u Zagrebu  Unknown Language   \n",
       "...     ...                                           ...               ...   \n",
       "30045  2023                           AME Medical Journal  Unknown Language   \n",
       "30046  2023               Video-Assisted Thoracic Surgery  Unknown Language   \n",
       "30047  2023                           AME Medical Journal  Unknown Language   \n",
       "30048  2023               Video-Assisted Thoracic Surgery  Unknown Language   \n",
       "30049  2023                           AME Medical Journal  Unknown Language   \n",
       "\n",
       "       CitedByCount                                        Affiliation  \n",
       "0                 0                           European Investment Bank  \n",
       "2                 0                           University of Montenegro  \n",
       "3                 0                       An-Najah National University  \n",
       "4                 0  Agusan del Sur State College of Agriculture an...  \n",
       "5                 0                Centre for Experimental Archaeology  \n",
       "...             ...                                                ...  \n",
       "30045             0                               Ospedale dell’Angelo  \n",
       "30046             0                                 NYU Langone Health  \n",
       "30047             0                          A.C.Camargo Cancer Center  \n",
       "30048             0  Centro de Tratamiento e Investigación sobre Cá...  \n",
       "30049             0                           Queen Elizabeth Hospital  \n",
       "\n",
       "[9657 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example of cleaned global dataframe ##\n",
    "\n",
    "global_df = pd.read_csv('scopus_combined_data_2018_2023.csv')\n",
    "\n",
    "global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with fine-tuned thresholding:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        AGRI       0.89      0.79      0.84       378\n",
      "        ARTS       0.92      0.74      0.82       104\n",
      "        BIOC       0.81      0.73      0.77       481\n",
      "        BUSI       0.73      0.81      0.77       133\n",
      "        CENG       0.87      0.82      0.84       312\n",
      "        CHEM       0.84      0.86      0.85       444\n",
      "        COMP       0.90      0.90      0.90       368\n",
      "        DECI       0.86      0.65      0.74        78\n",
      "        DENT       0.98      0.91      0.94        97\n",
      "        EART       0.87      0.67      0.75       126\n",
      "        ECON       0.78      0.67      0.72        81\n",
      "        ENER       0.90      0.80      0.84       205\n",
      "        ENGI       0.88      0.82      0.85       586\n",
      "        ENVI       0.85      0.83      0.84       362\n",
      "        HEAL       0.72      0.56      0.63        70\n",
      "        IMMU       0.85      0.77      0.81       232\n",
      "        MATE       0.87      0.88      0.88       406\n",
      "        MATH       0.87      0.72      0.78       137\n",
      "        MEDI       0.86      0.90      0.88      1124\n",
      "        MULT       0.99      0.94      0.96       234\n",
      "        NEUR       0.86      0.71      0.78       110\n",
      "        NURS       0.89      0.79      0.84        78\n",
      "        PHAR       0.82      0.80      0.81       209\n",
      "        PHYS       0.95      0.85      0.90       392\n",
      "        PSYC       1.00      0.48      0.65        42\n",
      "        SOCI       0.77      0.78      0.77       312\n",
      "        VETE       0.91      0.93      0.92       106\n",
      "\n",
      "   micro avg       0.86      0.82      0.84      7207\n",
      "   macro avg       0.87      0.78      0.82      7207\n",
      "weighted avg       0.87      0.82      0.84      7207\n",
      " samples avg       0.85      0.86      0.83      7207\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/im/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "## trend model to predict subject area of each research ##\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# using data from chula_data\n",
    "data = pd.read_csv(\"full_Chula_data.csv\").drop(columns=\"Cover-Date\")\n",
    "\n",
    "# Preprocessing\n",
    "X = data['Publication Name'] + \" \" + data['Title']  # Combine text columns\n",
    "y = data['Subject Area'].apply(lambda x: x.split(', ') if isinstance(x, str) else x)  # Split string back to list\n",
    "\n",
    "# Convert the text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english', ngram_range=(1, 2))\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "\n",
    "# MultiLabelBinarizer to handle multi-label classification\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_bin = mlb.fit_transform(y)  # Transform multi-label data into binary format\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model: RandomForest with One-vs-Rest strategy\n",
    "model = OneVsRestClassifier(RandomForestClassifier(random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the test set (for thresholding)\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# Initialize a matrix for thresholded predictions\n",
    "y_pred_thresholded = np.zeros(y_prob.shape)\n",
    "\n",
    "# Initialize list to store thresholds for each class\n",
    "thresholds_list = []\n",
    "\n",
    "# For each class, optimize the threshold based on precision-recall curve\n",
    "for i in range(y_prob.shape[1]):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test[:, i], y_prob[:, i])\n",
    "    \n",
    "    # Calculate F1-score for each threshold\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    # Choose the threshold based on the maximum F1-score\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    \n",
    "    # Append the best threshold for this class to the list\n",
    "    thresholds_list.append(best_threshold)\n",
    "    \n",
    "    # Apply the best threshold for this class\n",
    "    y_pred_thresholded[:, i] = (y_prob[:, i] >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluation: Use classification_report for detailed metrics\n",
    "print(\"Evaluation with fine-tuned thresholding:\")\n",
    "print(classification_report(y_test, y_pred_thresholded, target_names=mlb.classes_))\n",
    "\n",
    "# Now, you can save the thresholds_list for later use:\n",
    "# Example: Save thresholds_list to use later (if you need it for new predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'No Prediction': 0 out of 9657\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Language</th>\n",
       "      <th>CitedByCount</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Predicted Subject Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Social Progress for Resilient Regions</td>\n",
       "      <td>van Ballekom P.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Region</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>European Investment Bank</td>\n",
       "      <td>SOCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fashion language and translatology</td>\n",
       "      <td>Bojović B.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Babel</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>University of Montenegro</td>\n",
       "      <td>ARTS, SOCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A pragmatic framework to note-taking in consec...</td>\n",
       "      <td>Abuarrah S.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Babel</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>An-Najah National University</td>\n",
       "      <td>ECON, SOCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An Analytic Approximation to the Density of Tw...</td>\n",
       "      <td>Azura R.B.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Recoletos Multidisciplinary Research Journal</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Agusan del Sur State College of Agriculture an...</td>\n",
       "      <td>MEDI, ENGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DANCE MOTIFS ON PREHISTORIC POTTERY FROM EASTE...</td>\n",
       "      <td>Turčin I.</td>\n",
       "      <td>2018</td>\n",
       "      <td>Vjesnik Arheoloskog Muzeja u Zagrebu</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Centre for Experimental Archaeology</td>\n",
       "      <td>SOCI, ARTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9652</th>\n",
       "      <td>Second pleurectomy/decortication for a contral...</td>\n",
       "      <td>Furia S.</td>\n",
       "      <td>2023</td>\n",
       "      <td>AME Medical Journal</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Ospedale dell’Angelo</td>\n",
       "      <td>MEDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9653</th>\n",
       "      <td>Driving change and quality care in a healthcar...</td>\n",
       "      <td>Cerfolio R.J.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Video-Assisted Thoracic Surgery</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>NYU Langone Health</td>\n",
       "      <td>MEDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9654</th>\n",
       "      <td>Nephron-sparing surgery for small renal masses...</td>\n",
       "      <td>Gomes D.C.</td>\n",
       "      <td>2023</td>\n",
       "      <td>AME Medical Journal</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>A.C.Camargo Cancer Center</td>\n",
       "      <td>BIOC, MEDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9655</th>\n",
       "      <td>From video-assisted mediastinoscopy (VAM) to v...</td>\n",
       "      <td>Martínez S.</td>\n",
       "      <td>2023</td>\n",
       "      <td>Video-Assisted Thoracic Surgery</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Centro de Tratamiento e Investigación sobre Cá...</td>\n",
       "      <td>MEDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9656</th>\n",
       "      <td>Acute vision loss as an initial manifestation ...</td>\n",
       "      <td>Yong P.J.</td>\n",
       "      <td>2023</td>\n",
       "      <td>AME Medical Journal</td>\n",
       "      <td>Unknown Language</td>\n",
       "      <td>0</td>\n",
       "      <td>Queen Elizabeth Hospital</td>\n",
       "      <td>MEDI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9657 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title          Authors  \\\n",
       "0                 Social Progress for Resilient Regions  van Ballekom P.   \n",
       "1                    Fashion language and translatology       Bojović B.   \n",
       "2     A pragmatic framework to note-taking in consec...      Abuarrah S.   \n",
       "3     An Analytic Approximation to the Density of Tw...       Azura R.B.   \n",
       "4     DANCE MOTIFS ON PREHISTORIC POTTERY FROM EASTE...        Turčin I.   \n",
       "...                                                 ...              ...   \n",
       "9652  Second pleurectomy/decortication for a contral...         Furia S.   \n",
       "9653  Driving change and quality care in a healthcar...    Cerfolio R.J.   \n",
       "9654  Nephron-sparing surgery for small renal masses...       Gomes D.C.   \n",
       "9655  From video-assisted mediastinoscopy (VAM) to v...      Martínez S.   \n",
       "9656  Acute vision loss as an initial manifestation ...        Yong P.J.   \n",
       "\n",
       "      Year                                       Journal          Language  \\\n",
       "0     2018                                        Region  Unknown Language   \n",
       "1     2018                                         Babel  Unknown Language   \n",
       "2     2018                                         Babel  Unknown Language   \n",
       "3     2018  Recoletos Multidisciplinary Research Journal  Unknown Language   \n",
       "4     2018          Vjesnik Arheoloskog Muzeja u Zagrebu  Unknown Language   \n",
       "...    ...                                           ...               ...   \n",
       "9652  2023                           AME Medical Journal  Unknown Language   \n",
       "9653  2023               Video-Assisted Thoracic Surgery  Unknown Language   \n",
       "9654  2023                           AME Medical Journal  Unknown Language   \n",
       "9655  2023               Video-Assisted Thoracic Surgery  Unknown Language   \n",
       "9656  2023                           AME Medical Journal  Unknown Language   \n",
       "\n",
       "      CitedByCount                                        Affiliation  \\\n",
       "0                0                           European Investment Bank   \n",
       "1                0                           University of Montenegro   \n",
       "2                0                       An-Najah National University   \n",
       "3                0  Agusan del Sur State College of Agriculture an...   \n",
       "4                0                Centre for Experimental Archaeology   \n",
       "...            ...                                                ...   \n",
       "9652             0                               Ospedale dell’Angelo   \n",
       "9653             0                                 NYU Langone Health   \n",
       "9654             0                          A.C.Camargo Cancer Center   \n",
       "9655             0  Centro de Tratamiento e Investigación sobre Cá...   \n",
       "9656             0                           Queen Elizabeth Hospital   \n",
       "\n",
       "     Predicted Subject Area  \n",
       "0                      SOCI  \n",
       "1                ARTS, SOCI  \n",
       "2                ECON, SOCI  \n",
       "3                MEDI, ENGI  \n",
       "4                SOCI, ARTS  \n",
       "...                     ...  \n",
       "9652                   MEDI  \n",
       "9653                   MEDI  \n",
       "9654             BIOC, MEDI  \n",
       "9655                   MEDI  \n",
       "9656                   MEDI  \n",
       "\n",
       "[9657 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use the model to predicted subject area of each research in global_df ##\n",
    "\n",
    "# Step 1: Vectorize the new data\n",
    "\n",
    "new_df = global_df\n",
    "X_new = new_df['Journal'] + \" \" + new_df['Title']\n",
    "X_new_vect = vectorizer.transform(X_new)\n",
    "\n",
    "# Step 2: Predict probabilities using the trained model\n",
    "y_new_prob = model.predict_proba(X_new_vect)\n",
    "\n",
    "# Step 3: Apply thresholds and fallback strategies\n",
    "y_new_pred_thresholded = np.zeros(y_new_prob.shape)\n",
    "\n",
    "# Relaxed thresholds to reduce \"No Prediction\"\n",
    "relaxation_factor = 0.9  # Adjust this factor as needed\n",
    "for i in range(y_new_prob.shape[1]):\n",
    "    relaxed_threshold = thresholds_list[i] * relaxation_factor\n",
    "    y_new_pred_thresholded[:, i] = (y_new_prob[:, i] >= relaxed_threshold).astype(int)\n",
    "\n",
    "# Step 4: Convert predictions to labels with fallback\n",
    "y_new_pred = []\n",
    "for row, prob_row in zip(y_new_pred_thresholded, y_new_prob):\n",
    "    if np.all(row == 0):  # No prediction\n",
    "        # Fallback: Choose top 2 probabilities as labels\n",
    "        top_indices = np.argsort(prob_row)[-2:]  # Top 2 probabilities\n",
    "        fallback_labels = mlb.classes_[top_indices]\n",
    "        y_new_pred.append(list(fallback_labels))\n",
    "    else:\n",
    "        # Ensure 'row' is a 2D array when passed to `inverse_transform`\n",
    "        row_array = np.array(row).reshape(1, -1)\n",
    "        y_new_pred.append(mlb.inverse_transform(row_array)[0])\n",
    "\n",
    "# Step 5: Add predictions to the DataFrame\n",
    "new_df['Predicted Subject Area'] = [\n",
    "    ', '.join(labels) if labels else 'No Prediction' for labels in y_new_pred\n",
    "]\n",
    "\n",
    "# Step 6: Count and analyze results\n",
    "no_prediction_count = new_df['Predicted Subject Area'].value_counts().get('No Prediction', 0)\n",
    "print(f\"Number of 'No Prediction': {no_prediction_count} out of {len(new_df)}\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "new_df\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "new_df.to_csv(\"global_data_with_predicted_area (2018-2023).csv\", index=False)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Subject Area</th>\n",
       "      <th>AGRI</th>\n",
       "      <th>ARTS</th>\n",
       "      <th>BIOC</th>\n",
       "      <th>BUSI</th>\n",
       "      <th>CENG</th>\n",
       "      <th>CHEM</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DECI</th>\n",
       "      <th>DENT</th>\n",
       "      <th>EART</th>\n",
       "      <th>...</th>\n",
       "      <th>MATH</th>\n",
       "      <th>MEDI</th>\n",
       "      <th>MULT</th>\n",
       "      <th>NEUR</th>\n",
       "      <th>NURS</th>\n",
       "      <th>PHAR</th>\n",
       "      <th>PHYS</th>\n",
       "      <th>PSYC</th>\n",
       "      <th>SOCI</th>\n",
       "      <th>VETE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>95</td>\n",
       "      <td>55</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>158</td>\n",
       "      <td>490</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>202</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "      <td>148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>150</td>\n",
       "      <td>123</td>\n",
       "      <td>134</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>396</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "      <td>196</td>\n",
       "      <td>13</td>\n",
       "      <td>246</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>136</td>\n",
       "      <td>166</td>\n",
       "      <td>126</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>425</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>105</td>\n",
       "      <td>17</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>157</td>\n",
       "      <td>161</td>\n",
       "      <td>139</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>504</td>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "      <td>310</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>166</td>\n",
       "      <td>76</td>\n",
       "      <td>65</td>\n",
       "      <td>88</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>323</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>91</td>\n",
       "      <td>28</td>\n",
       "      <td>508</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>149</td>\n",
       "      <td>170</td>\n",
       "      <td>432</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>362</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>15</td>\n",
       "      <td>277</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Subject Area  AGRI  ARTS  BIOC  BUSI  CENG  CHEM  COMP  DECI  DENT  \\\n",
       "Year                                                                           \n",
       "2018                      95    55    88    64    77   158   490    49     6   \n",
       "2019                     150   123   134    44    54   102   102     6     6   \n",
       "2020                     136   166   126    34    26    85    82     1    17   \n",
       "2021                     157   161   139    56    55   100   107     5     7   \n",
       "2022                     166   239   166    76    65    88   103     4     4   \n",
       "2023                     149   170   432    46    18    70   136     5     5   \n",
       "\n",
       "Predicted Subject Area  EART  ...  MATH  MEDI  MULT  NEUR  NURS  PHAR  PHYS  \\\n",
       "Year                          ...                                             \n",
       "2018                     119  ...    49   202     4    14     2    26   131   \n",
       "2019                     117  ...    66   396    15    23    13    41   196   \n",
       "2020                      41  ...    56   425    33    25    23    29   105   \n",
       "2021                      39  ...   109   504    63    16    21    53   142   \n",
       "2022                      50  ...    56   323    36    15    15    32    91   \n",
       "2023                      42  ...    73   362    17     9    17    66    56   \n",
       "\n",
       "Predicted Subject Area  PSYC  SOCI  VETE  \n",
       "Year                                      \n",
       "2018                       7   148     5  \n",
       "2019                      13   246    10  \n",
       "2020                      17   350    11  \n",
       "2021                      34   310    13  \n",
       "2022                      28   508    27  \n",
       "2023                      15   277     3  \n",
       "\n",
       "[6 rows x 27 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Number of researchs based on predicted subject areas in each year ##\n",
    "\n",
    "new_df['Predicted Subject Area'] = new_df['Predicted Subject Area'].str.split(', ')  # Split multi-label entries into lists\n",
    "exploded_df = new_df.explode('Predicted Subject Area')  # Explode the lists into separate rows\n",
    "# Group by 'Year' and 'Predicted Subject Area', then count the occurrences\n",
    "subject_area_count = exploded_df.groupby(['Year', 'Predicted Subject Area']).size().reset_index(name='Count')\n",
    "\n",
    "test = subject_area_count.groupby(['Year', 'Predicted Subject Area'])['Count'].sum().reset_index()\n",
    "\n",
    "# Pivot the table to have 'Year' as the index and subject areas as columns\n",
    "pivoted_df = test.pivot_table(index='Year', columns='Predicted Subject Area', values='Count', aggfunc='sum')\n",
    "\n",
    "pivoted_df.to_csv(\"AreasCount_GlobalData.csv\", index=True)\n",
    "# Display the result\n",
    "pivoted_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Count</th>\n",
       "      <th>TotalCitedByCount</th>\n",
       "      <th>Normalized Count</th>\n",
       "      <th>Normalized TotalCitedByCount</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>BIOC</td>\n",
       "      <td>Jiangnan University</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>0.298136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>BIOC</td>\n",
       "      <td>Poznan University of Medical Sciences</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.030628</td>\n",
       "      <td>0.250568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>BIOC</td>\n",
       "      <td>Beijing Forestry University</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.052067</td>\n",
       "      <td>0.184586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>BIOC</td>\n",
       "      <td>Jilin University</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.029096</td>\n",
       "      <td>0.129419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>BIOC</td>\n",
       "      <td>Lovely Professional University</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.122068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>ENER</td>\n",
       "      <td>Jiangnan University</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.073507</td>\n",
       "      <td>0.191018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>ENER</td>\n",
       "      <td>Centre de Développement des Energies Renouvela...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.149422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>ENER</td>\n",
       "      <td>Beijing Forestry University</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.026034</td>\n",
       "      <td>0.104362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>ENER</td>\n",
       "      <td>Université de Batna 1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.097011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>ENER</td>\n",
       "      <td>Zhengzhou University</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.070444</td>\n",
       "      <td>0.093547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>ECON</td>\n",
       "      <td>Southwest State University</td>\n",
       "      <td>19</td>\n",
       "      <td>76</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.116386</td>\n",
       "      <td>0.469399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>ECON</td>\n",
       "      <td>Beijing Jiaotong University</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.417236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>ECON</td>\n",
       "      <td>Jiangnan University</td>\n",
       "      <td>10</td>\n",
       "      <td>59</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.090352</td>\n",
       "      <td>0.244347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>ECON</td>\n",
       "      <td>Beijing Forestry University</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.047473</td>\n",
       "      <td>0.159070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>ECON</td>\n",
       "      <td>Tianjin University of Science &amp;amp; Technology</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.105666</td>\n",
       "      <td>0.104114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area                                        Affiliation  Count  \\\n",
       "1431  BIOC                                Jiangnan University     12   \n",
       "1617  BIOC              Poznan University of Medical Sciences     11   \n",
       "1173  BIOC                        Beijing Forestry University      8   \n",
       "1443  BIOC                                   Jilin University      6   \n",
       "1500  BIOC                     Lovely Professional University      6   \n",
       "4781  ENER                                Jiangnan University      8   \n",
       "4704  ENER  Centre de Développement des Energies Renouvela...      7   \n",
       "4689  ENER                        Beijing Forestry University      5   \n",
       "4971  ENER                              Université de Batna 1      5   \n",
       "5001  ENER                               Zhengzhou University      4   \n",
       "4506  ECON                         Southwest State University     19   \n",
       "4274  ECON                        Beijing Jiaotong University     18   \n",
       "4377  ECON                                Jiangnan University     10   \n",
       "4272  ECON                        Beijing Forestry University      7   \n",
       "4545  ECON     Tianjin University of Science &amp; Technology      4   \n",
       "\n",
       "      TotalCitedByCount  Normalized Count  Normalized TotalCitedByCount  \\\n",
       "1431                 71          0.379310                      0.108729   \n",
       "1617                 20          0.344828                      0.030628   \n",
       "1173                 34          0.241379                      0.052067   \n",
       "1443                 19          0.172414                      0.029096   \n",
       "1500                  3          0.172414                      0.004594   \n",
       "4781                 48          0.241379                      0.073507   \n",
       "4704                 10          0.206897                      0.015314   \n",
       "4689                 17          0.137931                      0.026034   \n",
       "4971                  1          0.137931                      0.001531   \n",
       "5001                 46          0.103448                      0.070444   \n",
       "4506                 76          0.620690                      0.116386   \n",
       "4274                 15          0.586207                      0.022971   \n",
       "4377                 59          0.310345                      0.090352   \n",
       "4272                 31          0.206897                      0.047473   \n",
       "4545                 69          0.103448                      0.105666   \n",
       "\n",
       "         Score  \n",
       "1431  0.298136  \n",
       "1617  0.250568  \n",
       "1173  0.184586  \n",
       "1443  0.129419  \n",
       "1500  0.122068  \n",
       "4781  0.191018  \n",
       "4704  0.149422  \n",
       "4689  0.104362  \n",
       "4971  0.097011  \n",
       "5001  0.093547  \n",
       "4506  0.469399  \n",
       "4274  0.417236  \n",
       "4377  0.244347  \n",
       "4272  0.159070  \n",
       "4545  0.104114  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "area_df = pd.read_csv(\"global_data_with_predicted_area (2018-2023).csv\")\n",
    "area_df = area_df.assign(Area=area_df['Predicted Subject Area'].str.split(', ')).explode('Area')\n",
    "\n",
    "# Group by Area and Affiliation, aggregate Count and TotalCitedByCount\n",
    "area_affiliation_stats = (\n",
    "    area_df.groupby(['Area', 'Affiliation'])\n",
    "    .agg(Count=('Title', 'size'), TotalCitedByCount=('CitedByCount', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Normalize Count\n",
    "min_count = area_affiliation_stats['Count'].min()\n",
    "max_count = area_affiliation_stats['Count'].max()\n",
    "area_affiliation_stats['Normalized Count'] = (\n",
    "    area_affiliation_stats['Count'] - min_count\n",
    ") / (max_count - min_count)\n",
    "\n",
    "# Normalize TotalCitedByCount\n",
    "min_cited = area_affiliation_stats['TotalCitedByCount'].min()\n",
    "max_cited = area_affiliation_stats['TotalCitedByCount'].max()\n",
    "area_affiliation_stats['Normalized TotalCitedByCount'] = (\n",
    "    area_affiliation_stats['TotalCitedByCount'] - min_cited\n",
    ") / (max_cited - min_cited)\n",
    "\n",
    "\n",
    "w1 = 0.7  # Weight for Count\n",
    "w2 = 0.3  # Weight for TotalCitedByCount\n",
    "\n",
    "# Calculate weighted score\n",
    "area_affiliation_stats['Score'] = w1 * area_affiliation_stats['Normalized Count'] + w2 * area_affiliation_stats['Normalized TotalCitedByCount']\n",
    "\n",
    "# Sort and retrieve the top recommendations for each area\n",
    "top_recommendations = (\n",
    "    area_affiliation_stats\n",
    "    .sort_values(['Area', 'Score'], ascending=[True, False])\n",
    "    .groupby('Area')\n",
    "    .head(5)\n",
    ")\n",
    "\n",
    "\n",
    "bioc = top_recommendations[top_recommendations['Area'] == 'BIOC']\n",
    "ener = top_recommendations[top_recommendations['Area'] == 'ENER']\n",
    "econ = top_recommendations[top_recommendations['Area'] == 'ECON']\n",
    "\n",
    "# Combine the filtered dataframes\n",
    "combined = pd.concat([bioc, ener, econ])\n",
    "\n",
    "# Save the combined dataframe to a CSV file\n",
    "combined.to_csv(\"top_recommendations.csv\", index=False)\n",
    "\n",
    "combined\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
