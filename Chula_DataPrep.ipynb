{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "from flatten_json import flatten\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert all files to json ##\n",
    "\n",
    "directory = ['2018','2019','2020','2021','2022','2023']\n",
    "\n",
    "for year in directory:\n",
    "    for filename in os.listdir(year):\n",
    "        file_path = os.path.join(year, filename)\n",
    "        print(file_path)\n",
    "        \n",
    "        if os.path.isfile(file_path) and '.' not in filename:\n",
    "            new_file_path = f\"{file_path}.json\"\n",
    "            os.rename(file_path, new_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cover-Date</th>\n",
       "      <th>Publication Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Subject Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>Animal Bioscience</td>\n",
       "      <td>Microencapsulated basil oil (Ocimum basilicum ...</td>\n",
       "      <td>Thuekeaw S.</td>\n",
       "      <td>Asian-Australasian Association of Animal Produ...</td>\n",
       "      <td>AGRI, VETE, BIOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Journal of Neurosurgical Anesthesiology</td>\n",
       "      <td>Perceptions Regarding the SARS-CoV-2 Pandemic'...</td>\n",
       "      <td>Lele A.V.</td>\n",
       "      <td>Lippincott Williams and Wilkins</td>\n",
       "      <td>MEDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>International Journal of Neuroscience</td>\n",
       "      <td>Construction of a short version of the Montrea...</td>\n",
       "      <td>Hemrungrojn S.</td>\n",
       "      <td>Taylor and Francis Ltd.</td>\n",
       "      <td>NEUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>Journal of Applied Physics</td>\n",
       "      <td>The effect of strain and pressure on the elect...</td>\n",
       "      <td>Johansson E.</td>\n",
       "      <td>American Institute of Physics Inc.</td>\n",
       "      <td>PHYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Journal of Exercise Physiology Online</td>\n",
       "      <td>Dynamic Cardiopulmonary and Metabolic Function...</td>\n",
       "      <td>Masodsai K.</td>\n",
       "      <td>American Society of Exercise Physiologists</td>\n",
       "      <td>MEDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20211</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Frontiers in Artificial Intelligence and Appli...</td>\n",
       "      <td>Estimating actual evapotranspiration from NDVI...</td>\n",
       "      <td>Jermthaisong P.</td>\n",
       "      <td>IOS PressNieuwe Hemweg 6BAmsterdam1013 BG</td>\n",
       "      <td>COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20212</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>Scientific Reports</td>\n",
       "      <td>Genome-wide association study identified new s...</td>\n",
       "      <td>Sawai H.</td>\n",
       "      <td>Nature Publishing GroupHoundmillsBasingstoke, ...</td>\n",
       "      <td>MULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20213</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Journal of the Medical Association of Thailand</td>\n",
       "      <td>Effects of transcranial direct current stimula...</td>\n",
       "      <td>Utarapichat S.</td>\n",
       "      <td>Medical Association of Thailandmath@loxinfo.co.th</td>\n",
       "      <td>MEDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20214</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>Thai Journal of Veterinary Medicine</td>\n",
       "      <td>Prevalence and risk factors for canine cogniti...</td>\n",
       "      <td>Benjanirut C.</td>\n",
       "      <td>Chulalongkorn University Printing House39 Henr...</td>\n",
       "      <td>VETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20215</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>Economic Journal</td>\n",
       "      <td>Locus of Control and its Intergenerational Imp...</td>\n",
       "      <td>Lekfuangfu W.N.</td>\n",
       "      <td>Blackwell Publishing Ltdcustomerservices@oxonb...</td>\n",
       "      <td>ECON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20215 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cover-Date                                   Publication Name  \\\n",
       "0      2022-05-01                                  Animal Bioscience   \n",
       "1      2022-04-01            Journal of Neurosurgical Anesthesiology   \n",
       "2      2022-01-01              International Journal of Neuroscience   \n",
       "3      2022-02-14                         Journal of Applied Physics   \n",
       "4      2022-01-01              Journal of Exercise Physiology Online   \n",
       "...           ...                                                ...   \n",
       "20211  2018-01-01  Frontiers in Artificial Intelligence and Appli...   \n",
       "20212  2018-12-01                                 Scientific Reports   \n",
       "20213  2018-01-01     Journal of the Medical Association of Thailand   \n",
       "20214  2018-09-01                Thai Journal of Veterinary Medicine   \n",
       "20215  2018-02-01                                   Economic Journal   \n",
       "\n",
       "                                                   Title           Author  \\\n",
       "0      Microencapsulated basil oil (Ocimum basilicum ...      Thuekeaw S.   \n",
       "1      Perceptions Regarding the SARS-CoV-2 Pandemic'...        Lele A.V.   \n",
       "2      Construction of a short version of the Montrea...   Hemrungrojn S.   \n",
       "3      The effect of strain and pressure on the elect...     Johansson E.   \n",
       "4      Dynamic Cardiopulmonary and Metabolic Function...      Masodsai K.   \n",
       "...                                                  ...              ...   \n",
       "20211  Estimating actual evapotranspiration from NDVI...  Jermthaisong P.   \n",
       "20212  Genome-wide association study identified new s...         Sawai H.   \n",
       "20213  Effects of transcranial direct current stimula...   Utarapichat S.   \n",
       "20214  Prevalence and risk factors for canine cogniti...    Benjanirut C.   \n",
       "20215  Locus of Control and its Intergenerational Imp...  Lekfuangfu W.N.   \n",
       "\n",
       "                                               Publisher      Subject Area  \n",
       "0      Asian-Australasian Association of Animal Produ...  AGRI, VETE, BIOC  \n",
       "1                        Lippincott Williams and Wilkins              MEDI  \n",
       "2                                Taylor and Francis Ltd.              NEUR  \n",
       "3                     American Institute of Physics Inc.              PHYS  \n",
       "4             American Society of Exercise Physiologists              MEDI  \n",
       "...                                                  ...               ...  \n",
       "20211          IOS PressNieuwe Hemweg 6BAmsterdam1013 BG              COMP  \n",
       "20212  Nature Publishing GroupHoundmillsBasingstoke, ...              MULT  \n",
       "20213  Medical Association of Thailandmath@loxinfo.co.th              MEDI  \n",
       "20214  Chulalongkorn University Printing House39 Henr...              VETE  \n",
       "20215  Blackwell Publishing Ltdcustomerservices@oxonb...              ECON  \n",
       "\n",
       "[20215 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ## convert data into csv (includes only interested topics) ##\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Process a single JSON file to extract required data.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract publication metadata\n",
    "        coredata = data.get('abstracts-retrieval-response', {}).get('coredata', {})\n",
    "        cover_date = data.get('abstracts-retrieval-response', {}).get('coredata', {}).get('prism:coverDate', None)\n",
    "        publication_name = coredata.get('prism:publicationName', 'Unknown')\n",
    "        title = coredata.get('dc:title', 'Unknown')\n",
    "        author = coredata.get('dc:creator', {}).get('author', [{}])[0].get('ce:indexed-name', 'Unknown')\n",
    "        publisher = coredata.get('dc:publisher', 'Unknown')\n",
    "\n",
    "        # Extract subject areas\n",
    "        subject_areas = data.get('abstracts-retrieval-response', {}).get('subject-areas', {}).get('subject-area', [])\n",
    "        subject_abbrevs = [area.get('@abbrev', 'Unknown') for area in subject_areas]\n",
    "\n",
    "\n",
    "        # Return as list of records\n",
    "        return [\n",
    "            {   \"Cover-Date\": cover_date,\n",
    "                \"Publication Name\": publication_name,\n",
    "                \"Title\": title,\n",
    "                \"Author\": author,\n",
    "                \"Publisher\": publisher,\n",
    "                \"Subject Area\":list(set(subject_abbrevs))\n",
    "            }\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_all_files_to_dataframe(base_dir):\n",
    "    \"\"\"Process all files and return a DataFrame with the required columns.\"\"\"\n",
    "    all_records = []\n",
    "\n",
    "    for year_folder in os.listdir(base_dir):\n",
    "        year_path = os.path.join(base_dir, year_folder)\n",
    "        if os.path.isdir(year_path):\n",
    "            for file_name in os.listdir(year_path):\n",
    "                file_path = os.path.join(year_path, file_name)\n",
    "                if file_path.endswith('.json'):\n",
    "                    # Process each JSON file and collect records\n",
    "                    records = process_file(file_path)\n",
    "                    all_records.extend(records)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "# Base directory where project files are stored\n",
    "base_dir = \"/Users/im/Documents/Data Sci/Project/Project/chulaDatabase\"\n",
    "\n",
    "# Process all files and create DataFrame\n",
    "df = process_all_files_to_dataframe(base_dir)\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df['Subject Area'] = df['Subject Area'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "# drop null and duplicate values\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "# Save to a CSV for analysis\n",
    "output_file = \"full_Chula_data.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display first few rows of the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGRI</th>\n",
       "      <th>ARTS</th>\n",
       "      <th>BIOC</th>\n",
       "      <th>BUSI</th>\n",
       "      <th>CENG</th>\n",
       "      <th>CHEM</th>\n",
       "      <th>COMP</th>\n",
       "      <th>DECI</th>\n",
       "      <th>DENT</th>\n",
       "      <th>EART</th>\n",
       "      <th>...</th>\n",
       "      <th>MATH</th>\n",
       "      <th>MEDI</th>\n",
       "      <th>MULT</th>\n",
       "      <th>NEUR</th>\n",
       "      <th>NURS</th>\n",
       "      <th>PHAR</th>\n",
       "      <th>PHYS</th>\n",
       "      <th>PSYC</th>\n",
       "      <th>SOCI</th>\n",
       "      <th>VETE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>254</td>\n",
       "      <td>33</td>\n",
       "      <td>343</td>\n",
       "      <td>71</td>\n",
       "      <td>199</td>\n",
       "      <td>302</td>\n",
       "      <td>236</td>\n",
       "      <td>33</td>\n",
       "      <td>57</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>749</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>38</td>\n",
       "      <td>153</td>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>157</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>231</td>\n",
       "      <td>79</td>\n",
       "      <td>370</td>\n",
       "      <td>100</td>\n",
       "      <td>214</td>\n",
       "      <td>314</td>\n",
       "      <td>358</td>\n",
       "      <td>87</td>\n",
       "      <td>52</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>842</td>\n",
       "      <td>101</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>151</td>\n",
       "      <td>384</td>\n",
       "      <td>21</td>\n",
       "      <td>203</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>321</td>\n",
       "      <td>86</td>\n",
       "      <td>381</td>\n",
       "      <td>124</td>\n",
       "      <td>242</td>\n",
       "      <td>330</td>\n",
       "      <td>294</td>\n",
       "      <td>86</td>\n",
       "      <td>50</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>907</td>\n",
       "      <td>147</td>\n",
       "      <td>73</td>\n",
       "      <td>45</td>\n",
       "      <td>180</td>\n",
       "      <td>355</td>\n",
       "      <td>34</td>\n",
       "      <td>222</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>354</td>\n",
       "      <td>110</td>\n",
       "      <td>461</td>\n",
       "      <td>100</td>\n",
       "      <td>313</td>\n",
       "      <td>440</td>\n",
       "      <td>286</td>\n",
       "      <td>31</td>\n",
       "      <td>82</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>1107</td>\n",
       "      <td>256</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>196</td>\n",
       "      <td>373</td>\n",
       "      <td>37</td>\n",
       "      <td>320</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>431</td>\n",
       "      <td>108</td>\n",
       "      <td>515</td>\n",
       "      <td>126</td>\n",
       "      <td>335</td>\n",
       "      <td>447</td>\n",
       "      <td>402</td>\n",
       "      <td>80</td>\n",
       "      <td>105</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>1230</td>\n",
       "      <td>309</td>\n",
       "      <td>97</td>\n",
       "      <td>78</td>\n",
       "      <td>237</td>\n",
       "      <td>338</td>\n",
       "      <td>64</td>\n",
       "      <td>366</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>310</td>\n",
       "      <td>86</td>\n",
       "      <td>366</td>\n",
       "      <td>81</td>\n",
       "      <td>252</td>\n",
       "      <td>328</td>\n",
       "      <td>250</td>\n",
       "      <td>36</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>804</td>\n",
       "      <td>191</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>139</td>\n",
       "      <td>234</td>\n",
       "      <td>46</td>\n",
       "      <td>247</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AGRI  ARTS  BIOC  BUSI  CENG  CHEM  COMP  DECI  DENT  EART  ...  MATH  \\\n",
       "Year                                                              ...         \n",
       "2018   254    33   343    71   199   302   236    33    57   103  ...   101   \n",
       "2019   231    79   370   100   214   314   358    87    52   108  ...   124   \n",
       "2020   321    86   381   124   242   330   294    86    50   148  ...   127   \n",
       "2021   354   110   461   100   313   440   286    31    82   142  ...   124   \n",
       "2022   431   108   515   126   335   447   402    80   105   109  ...   154   \n",
       "2023   310    86   366    81   252   328   250    36   101   103  ...   110   \n",
       "\n",
       "      MEDI  MULT  NEUR  NURS  PHAR  PHYS  PSYC  SOCI  VETE  \n",
       "Year                                                        \n",
       "2018   749    84    84    38   153   388    24   157   106  \n",
       "2019   842   101    84    33   151   384    21   203    84  \n",
       "2020   907   147    73    45   180   355    34   222    91  \n",
       "2021  1107   256    86    67   196   373    37   320   109  \n",
       "2022  1230   309    97    78   237   338    64   366   141  \n",
       "2023   804   191    81    60   139   234    46   247    60  \n",
       "\n",
       "[6 rows x 27 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Number of researchs based on subject areas in each year ##\n",
    "\n",
    "df['Year'] = pd.to_datetime(df['Cover-Date']).dt.year\n",
    "\n",
    "# Split 'Subject Area' into individual entries\n",
    "df = df.assign(Subject_Area=df['Subject Area'].str.split(', '))\n",
    "\n",
    "# Explode the 'Subject Area' list into separate rows\n",
    "df = df.explode('Subject_Area')\n",
    "\n",
    "# Group by 'Year' and 'Subject_Area' and count occurrences\n",
    "grouped = df.groupby(['Year', 'Subject_Area']).size().reset_index(name='Count')\n",
    "\n",
    "# Pivot the data to reshape it\n",
    "pivot_table = grouped.pivot(index='Year', columns='Subject_Area', values='Count').fillna(0).astype(int)\n",
    "pivot_table.columns.name = None\n",
    "\n",
    "pivot_table.to_csv('areasCount_ChulaData.csv', index=True)\n",
    "\n",
    "\n",
    "pivot_table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
